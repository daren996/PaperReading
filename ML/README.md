# MachineLearning

Some resources about machine learning.



## History 

1. 1948 克劳德·香农介绍了信息论，这是决策树学习的基础之一。Shannon, C.E. (1948).A mathematical theory of communication*.* Bell System Technical Journal, 27: 379–423 and 623–656. //Shannon, C. E. (1949). Communication Theory of Secrecy Systems. Bell System Technical Journal 28 (4): 656–715.
2. 1963 Morgan和Sonquist开发出第一个回归树 Morgan. J. N. & Sonquist, J. A. (1963) Problems in the Analysis of Survey Data, and a Proposal, Journal of the American Statistical Association, 58:302, 415-434.
3. 1980 Gordon V. Kass开发出CHAID算法 Gordon V. K. (1980).An Exploratory Technique for Investigating Large Quantities of Categorical Data, Applied Statistics. 29(2): 119–127.
4. 1984 Leo Breiman et al.开发出CART（分类与回归树） Breiman, L.; Friedman, J. H., Olshen, R. A., & Stone, C. J. (1984). Classification and regression trees. Monterey, CA: Wadsworth & Brooks/Cole Advanced Books & Software.
5. 1986 Quinlan开发出ID3算法 Quinlan, J. R. (1986). Induction of Decision Trees. Mach. Learn. 1(1): 81–106
6. 1993 Quinlan开发出C4.5算法 Quinlan, J. R. (1993). C4.5: Programs for machine learning. San Francisco,CA: Morgan Kaufman.
7. 1997 Loh和Shih开发出QUEST Loh, W. Y., & Shih, Y. S. (1997). Split selection methods for classification trees. Statistica sinica, 815-840.
8. 1999 Yoav Freund和Llew Mason提出AD-Tree Freund, Y., & Mason, L. (1999, June). The alternating decision tree learning algorithm. In icml (Vol. 99, pp. 124-133).
9. 2017 Geoffrey Hinton等人发表arXiv论文提出「软决策树」（Soft Decision Tree） Frosst, N.; Hinton, G. (2017).Distilling a Neural Network Into a Soft Decision Tree.arXiv:1711.09784.
10. 2018 加州大学洛杉矶分校的朱松纯教授等人发布了一篇使用决策树对CNN的表征和预测进行解释的论文 Zhang, Q.; Yang, Y.; Nian Wu, Y.; Zhu, S-C. (2018). Interpreting CNNs via Decision Trees. arXiv:1802.00121.





## Scikit Learn

[Decision Tree Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)

[Count Vectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html): Convert a collection of text documents to a matrix of token counts. 

Model Selection. 
1. [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split): split arrays or matrices into random train and test subsets. 
2. [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score): evaluate a score by cross-validation. 



## Discription

[Course CSC2515](http://www.cs.toronto.edu/~rgrosse/courses/csc2515_2019/): A Course I took part in at the University of Toronto.

[Information Theory](https://homes.cs.washington.edu/~anuprao/pubs/CSE533Autumn2010/): Useful slides about Information Theory from the Univ. of Washington.  





### 